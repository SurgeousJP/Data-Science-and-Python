{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network for MNIST Classification\n",
    "\n",
    "We'll apply all the knowledge from the lectures in this section to write a deep neural network. The problem we've chosen is referred to as the \"Hello World\" of deep learning because for most students it is the first deep learning algorithm they see.\n",
    "\n",
    "The dataset is called MNIST and refers to handwritten digit recognition. You can find more about it on Yann LeCun's website (Director of AI Research, Facebook). He is one of the pioneers of what we've been talking about and of more complex approaches that are widely used today, such as covolutional neural networks (CNNs). \n",
    "\n",
    "The dataset provides 70,000 images (28x28 pixels) of handwritten digits (1 digit per image). \n",
    "\n",
    "The goal is to write an algorithm that detects which digit is written. Since there are only 10 digits (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), this is a classification problem with 10 classes. \n",
    "\n",
    "Our goal would be to build a neural network with 2 hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# TensorFLow includes a data provider for MNIST that we'll use.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# It comes with the tensorflow-datasets module, therefore, if you haven't please install the package using\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# pip install tensorflow-datasets \u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# or\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# conda install tensorflow-datasets\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfds\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# these datasets will be stored in C:\\Users\\*USERNAME*\\tensorflow_datasets\\...\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# the first time you download a dataset, it is stored in the respective folder \u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# every other time, it is automatically loading the copy on your computer \u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_datasets\\__init__.py:46\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,g-bad-import-order,wrong-import-position\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Ensure TensorFlow is importable and its version is sufficiently recent. This\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# needs to happen before anything else, since the imports below will try to\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# import tensorflow, too.\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_compat\n\u001b[0;32m     47\u001b[0m tf_compat\u001b[38;5;241m.\u001b[39mensure_tf_install()\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Imports for registration\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_datasets\\core\\__init__.py:21\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Ensure TensorFlow is importable and its version is sufficiently recent. This\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# needs to happen before anything else, since the imports below will try to\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# import tensorflow, too.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_compat\n\u001b[1;32m---> 21\u001b[0m \u001b[43mtf_compat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mensure_tf_install\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeamBasedBuilder  \u001b[38;5;66;03m# pylint:disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BuilderConfig\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_datasets\\core\\tf_compat.py:57\u001b[0m, in \u001b[0;36mensure_tf_install\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFailed to import TensorFlow. Please note that TensorFlow is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstalled by default when you install TensorFlow Datasets. This is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mso that users can decide whether to install the GPU-enabled \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorFlow package. To use TensorFlow Datasets, please install the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmost recent version of TensorFlow, by following instructions at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://tensorflow.org/install.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m tf_version \u001b[38;5;241m=\u001b[39m distutils\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39mLooseVersion(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m)\n\u001b[0;32m     58\u001b[0m v_1_13 \u001b[38;5;241m=\u001b[39m distutils\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39mLooseVersion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.13.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf_version \u001b[38;5;241m<\u001b[39m v_1_13:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# TensorFLow includes a data provider for MNIST that we'll use.\n",
    "# It comes with the tensorflow-datasets module, therefore, if you haven't please install the package using\n",
    "# pip install tensorflow-datasets \n",
    "# or\n",
    "# conda install tensorflow-datasets\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# these datasets will be stored in C:\\Users\\*USERNAME*\\tensorflow_datasets\\...\n",
    "# the first time you download a dataset, it is stored in the respective folder \n",
    "# every other time, it is automatically loading the copy on your computer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "That's where we load and preprocess our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# remember the comment from above\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# these datasets will be stored in C:\\Users\\*USERNAME*\\tensorflow_datasets\\...\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# the first time you download a dataset, it is stored in the respective folder \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# there are other arguments we can specify, which we can find useful\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# mnist_dataset = tfds.load(name='mnist', as_supervised=True)\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m mnist_dataset, mnist_info \u001b[38;5;241m=\u001b[39m \u001b[43mtfds\u001b[49m\u001b[38;5;241m.\u001b[39mload(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmnist\u001b[39m\u001b[38;5;124m'\u001b[39m, with_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, as_supervised\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# with_info=True will also provide us with a tuple containing information about the version, features, number of samples\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# we will use this information a bit below and we will store it in mnist_info\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# as_supervised=True will load the dataset in a 2-tuple structure (input, target) \u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# alternatively, as_supervised=False, would return a dictionary\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# obviously we prefer to have our inputs and targets separated \u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tfds' is not defined"
     ]
    }
   ],
   "source": [
    "# remember the comment from above\n",
    "# these datasets will be stored in C:\\Users\\*USERNAME*\\tensorflow_datasets\\...\n",
    "# the first time you download a dataset, it is stored in the respective folder \n",
    "# every other time, it is automatically loading the copy on your computer \n",
    "\n",
    "# tfds.load actually loads a dataset (or downloads and then loads if that's the first time you use it) \n",
    "# in our case, we are interesteed in the MNIST; the name of the dataset is the only mandatory argument\n",
    "# there are other arguments we can specify, which we can find useful\n",
    "# mnist_dataset = tfds.load(name='mnist', as_supervised=True)\n",
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
    "# with_info=True will also provide us with a tuple containing information about the version, features, number of samples\n",
    "# we will use this information a bit below and we will store it in mnist_info\n",
    "\n",
    "# as_supervised=True will load the dataset in a 2-tuple structure (input, target) \n",
    "# alternatively, as_supervised=False, would return a dictionary\n",
    "# obviously we prefer to have our inputs and targets separated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-TF2.0",
   "language": "python",
   "name": "py3-tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
